{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Using the tf-idf Representation\n",
    "\n",
    "Attempt which uses no word embeddings at all.\n",
    "This gets about 0.79 on Kaggle with very little custom tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN = os.path.join('..', 'data', 'train')\n",
    "TEST = os.path.join('..', 'data', 'test')\n",
    "POS_TWEET_FILE = os.path.join(TRAIN, 'train_pos_full.txt')\n",
    "NEG_TWEET_FILE = os.path.join(TRAIN, 'train_neg_full.txt')\n",
    "TEST_TWEET_FILE = os.path.join(TEST, 'test_data.txt')\n",
    "EMBEDDING_SIZE = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_tweets(fname):\n",
    "    \"\"\"Read the tweets in the given file.\"\"\"\n",
    "    with open(fname, 'r') as f:\n",
    "        return [l for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_tweets = read_tweets(POS_TWEET_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_tweets = read_tweets(NEG_TWEET_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_tweets = read_tweets(TEST_TWEET_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2510000\n"
     ]
    }
   ],
   "source": [
    "# sentences = pos_tweets + neg_tweets + test_tweets\n",
    "lim = 1250000\n",
    "sentences = pos_tweets[:lim] + neg_tweets[:lim] + test_tweets[:lim]\n",
    "y_full = [+1] * lim + [-1] * lim\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2510000, 444159)\n",
      "Shape after removing validation data: (2500000, 444159)\n"
     ]
    }
   ],
   "source": [
    "X_full = vectorizer.fit_transform(sentences)\n",
    "print(X_full.shape)\n",
    "\n",
    "X_valid = X_full[-10000:]\n",
    "X_full = X_full[:-10000]\n",
    "\n",
    "print(\"Shape after removing validation data: {0}\".format(X_full.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 191032)\t0.425446586829\n",
      "  (0, 278934)\t0.56536793347\n",
      "  (0, 427085)\t0.57178154977\n",
      "  (0, 227970)\t0.288475958544\n",
      "  (0, 385380)\t0.229710816262\n",
      "  (0, 205058)\t0.190878817935\n",
      "\n",
      "  (0, 326023)\t0.579803551963\n",
      "  (0, 395768)\t0.666397465816\n",
      "  (0, 151313)\t0.468766742298\n"
     ]
    }
   ],
   "source": [
    "print(X_full[220])\n",
    "print()\n",
    "print(X_full[2555])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import *\n",
    "from sklearn.metrics import *\n",
    "\n",
    "grid = {\n",
    "    'loss': ['hinge', 'log'],\n",
    "    'alpha': [1e-6, 5e-6, 0.00001, 0.00005, 0.0001, 0.0005],\n",
    "}\n",
    "\n",
    "def report(grid_scores, n_top=3):\n",
    "    top_scores = sorted(grid_scores, key=lambda x: x[1], reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"{2}: Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "              score.mean_validation_score,\n",
    "              np.std(score.cv_validation_scores),\n",
    "              i + 1))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_tfidf():\n",
    "    gs = GridSearchCV(SGDClassifier(), grid, cv=5, verbose=True, n_jobs=4)\n",
    "    print(\"Starting grid search...\")\n",
    "    res = gs.fit(X_full, y_full)\n",
    "    report(res.grid_scores_, n_top=25)\n",
    "    \n",
    "    predY = res.predict(X_full)\n",
    "    acc = accuracy_score(y_full, predY)\n",
    "    f1 = accuracy_score(y_full, predY)\n",
    "    \n",
    "    print(\"Train accuracy: {0}\\nTrain F1 score: {1}\".format(acc, f1))\n",
    "    \n",
    "    return res  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting grid search...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Mean validation score: 0.801 (std: 0.001)\n",
      "Parameters: {'alpha': 1e-06, 'loss': 'hinge'}\n",
      "\n",
      "2: Mean validation score: 0.801 (std: 0.001)\n",
      "Parameters: {'alpha': 1e-06, 'loss': 'log'}\n",
      "\n",
      "3: Mean validation score: 0.800 (std: 0.001)\n",
      "Parameters: {'alpha': 5e-06, 'loss': 'hinge'}\n",
      "\n",
      "4: Mean validation score: 0.797 (std: 0.001)\n",
      "Parameters: {'alpha': 1e-05, 'loss': 'hinge'}\n",
      "\n",
      "5: Mean validation score: 0.795 (std: 0.001)\n",
      "Parameters: {'alpha': 5e-06, 'loss': 'log'}\n",
      "\n",
      "6: Mean validation score: 0.791 (std: 0.001)\n",
      "Parameters: {'alpha': 1e-05, 'loss': 'log'}\n",
      "\n",
      "7: Mean validation score: 0.784 (std: 0.001)\n",
      "Parameters: {'alpha': 5e-05, 'loss': 'hinge'}\n",
      "\n",
      "8: Mean validation score: 0.776 (std: 0.002)\n",
      "Parameters: {'alpha': 0.0001, 'loss': 'hinge'}\n",
      "\n",
      "9: Mean validation score: 0.775 (std: 0.002)\n",
      "Parameters: {'alpha': 5e-05, 'loss': 'log'}\n",
      "\n",
      "10: Mean validation score: 0.764 (std: 0.002)\n",
      "Parameters: {'alpha': 0.0001, 'loss': 'log'}\n",
      "\n",
      "11: Mean validation score: 0.747 (std: 0.002)\n",
      "Parameters: {'alpha': 0.0005, 'loss': 'hinge'}\n",
      "\n",
      "12: Mean validation score: 0.738 (std: 0.002)\n",
      "Parameters: {'alpha': 0.0005, 'loss': 'log'}\n",
      "\n",
      "Train accuracy: 0.8197236\n",
      "Train F1 score: 0.8197236\n"
     ]
    }
   ],
   "source": [
    "res = eval_tfidf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kaggle_tfidf = res.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "timestamp = int(time.time())\n",
    "\n",
    "with open('../data/output/pred-tfidf-{0}.csv'.format(timestamp), 'w') as f:\n",
    "    f.write(\"Id,Prediction\\n\")\n",
    "    for i, pred in enumerate(kaggle_tfidf):\n",
    "        f.write(\"{0},{1}\\n\".format(i + 1, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
